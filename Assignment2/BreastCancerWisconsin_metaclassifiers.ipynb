{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unaiz\\AppData\\Local\\Temp\\ipykernel_15976\\2628873864.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['Diagnosis'] = y['Diagnosis'].map({'M': 1, 'B': 0}) #change binary labels 'M' to 1 and 'B' to 0\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "  \n",
    "# metadata \n",
    "#print(breast_cancer_wisconsin_diagnostic.metadata) \n",
    "  \n",
    "# variable information \n",
    "#print(breast_cancer_wisconsin_diagnostic.variables) \n",
    "\n",
    "\n",
    "y['Diagnosis'] = y['Diagnosis'].map({'M': 1, 'B': 0}) #change binary labels 'M' to 1 and 'B' to 0\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an untrained instance of QDA\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Set up Bagging with QDA as the base estimator\n",
    "bagging_model = BaggingClassifier(estimator=qda, n_estimators=10, random_state=42)\n",
    "bagging_model.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = bagging_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Boosting for Linear Discriminant Analysis due to: LinearDiscriminantAnalysis doesn't support sample_weight.\n",
      "Skipping Boosting for Quadratic Discriminant Analysis due to: QuadraticDiscriminantAnalysis doesn't support sample_weight.\n",
      "                        Classifier    Method  F1 Score\n",
      "0              Logistic Regression   Bagging  0.964706\n",
      "1              Logistic Regression  Boosting  0.976744\n",
      "2     Linear Discriminant Analysis   Bagging  0.939759\n",
      "3  Quadratic Discriminant Analysis   Bagging  0.921348\n",
      "4             Gaussian Naive Bayes   Bagging  0.952381\n",
      "5             Gaussian Naive Bayes  Boosting  0.939759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unaiz\\AppData\\Local\\Temp\\ipykernel_15976\\2445468292.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame({\"Classifier\": [name], \"Method\": [\"Bagging\"], \"F1 Score\": [f1_bagging]})], ignore_index=True)\n",
      "c:\\Users\\unaiz\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\unaiz\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\unaiz\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\unaiz\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42),\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "    \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Split the data and scale it\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize a results table\n",
    "results = pd.DataFrame(columns=[\"Classifier\", \"Method\", \"F1 Score\"])\n",
    "\n",
    "# Loop over classifiers and apply Bagging and Boosting\n",
    "for name, clf in classifiers.items():\n",
    "    # Bagging\n",
    "    bagging_model = BaggingClassifier(estimator=clf, n_estimators=10, random_state=42)\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "    y_pred_bagging = bagging_model.predict(X_test)\n",
    "    f1_bagging = f1_score(y_test, y_pred_bagging)\n",
    "    \n",
    "    # Store Bagging results\n",
    "    results = pd.concat([results, pd.DataFrame({\"Classifier\": [name], \"Method\": [\"Bagging\"], \"F1 Score\": [f1_bagging]})], ignore_index=True)\n",
    "    \n",
    "    # Boosting (only apply if the classifier supports sample_weight)\n",
    "    try:\n",
    "        boosting_model = AdaBoostClassifier(estimator=clf, n_estimators=10, random_state=42)\n",
    "        boosting_model.fit(X_train, y_train)\n",
    "        y_pred_boosting = boosting_model.predict(X_test)\n",
    "        f1_boosting = f1_score(y_test, y_pred_boosting)\n",
    "        \n",
    "        # Store Boosting results\n",
    "        results = pd.concat([results, pd.DataFrame({\"Classifier\": [name], \"Method\": [\"Boosting\"], \"F1 Score\": [f1_boosting]})], ignore_index=True)\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping Boosting for {name} due to: {e}\")\n",
    "\n",
    "# Display the results table\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
